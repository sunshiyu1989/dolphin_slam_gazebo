#!/usr/bin/env python3
"""
Dolphin SLAM - æ•°æ®é›†åˆ†æå·¥å…·
åˆ†æ AUV-Based Multi-Sensor Dataset å¹¶ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
æ”¯æŒä»é…ç½®æ–‡ä»¶è‡ªåŠ¨è¯»å–è·¯å¾„
"""

import argparse
import os
import pandas as pd
import numpy as np
import cv2
import matplotlib.pyplot as plt
from datetime import datetime
from tqdm import tqdm
import json
import yaml

class DatasetAnalyzer:
    """åˆ†æ AUV æ•°æ®é›†"""
    
    def __init__(self, dataset_path=None, config_file=None):
        if config_file and os.path.exists(config_file):
            # ä»é…ç½®æ–‡ä»¶è¯»å–è·¯å¾„
            self.dataset_path = self.load_path_from_config(config_file)
            print(f"ä»é…ç½®æ–‡ä»¶è¯»å–æ•°æ®é›†è·¯å¾„: {self.dataset_path}")
        elif dataset_path:
            self.dataset_path = dataset_path
        else:
            raise ValueError("å¿…é¡»æä¾› dataset_path æˆ– config_file")
            
        self.file_paths = {}  # å­˜å‚¨å®é™…æ‰¾åˆ°çš„æ–‡ä»¶è·¯å¾„
        self.report = {
            'dataset_path': self.dataset_path,
            'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'camera': {},
            'sonar': {},
            'navigation': {},
            'synchronization': {},
            'quality_metrics': {}
        }
        
    def load_path_from_config(self, config_file):
        """ä» YAML é…ç½®æ–‡ä»¶åŠ è½½æ•°æ®é›†è·¯å¾„"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # æ£€æŸ¥ä¸åŒçš„è·¯å¾„é…ç½®æ ¼å¼
            if 'dolphin_slam' in config and 'dataset' in config['dolphin_slam']:
                # æ–°æ ¼å¼ï¼šdolphin_slam.dataset.base_path
                dataset_config = config['dolphin_slam']['dataset']
                if 'base_path' in dataset_config:
                    return dataset_config['base_path']
                elif 'camera_path' in dataset_config:
                    # ä» camera_path æ¨å¯¼ base_path
                    return os.path.dirname(dataset_config['camera_path'])
                    
            elif 'bio_slam_node' in config:
                # æ—§æ ¼å¼ï¼šbio_slam_node.ros__parameters
                params = config['bio_slam_node']['ros__parameters']
                if 'image_path' in params:
                    # ä» image_path æ¨å¯¼æ•°æ®é›†æ ¹ç›®å½•
                    return os.path.dirname(os.path.dirname(params['image_path']))
                    
            # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›é»˜è®¤è·¯å¾„
            raise ValueError("é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®é›†è·¯å¾„")
            
        except Exception as e:
            print(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            raise
            
    def analyze(self):
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®é›†åˆ†æ"""
        print(f"åˆ†ææ•°æ®é›†: {self.dataset_path}")
        
        # æ£€æŸ¥æ•°æ®é›†ç»“æ„
        if not self.check_dataset_structure():
            return False
            
        # åˆ†æå„ä¸ªæ¨¡æ€
        self.analyze_navigation()
        self.analyze_camera()
        self.analyze_sonar() 
        self.analyze_synchronization()
        self.analyze_quality()
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
        
        return True
        
    def check_dataset_structure(self):
        """æ£€æŸ¥æ•°æ®é›†ç»“æ„æ˜¯å¦å®Œæ•´"""
        if not os.path.exists(self.dataset_path):
            print(f"é”™è¯¯ï¼šæ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨ {self.dataset_path}")
            return False
            
        # æ£€æŸ¥æ–‡ä»¶ï¼ˆæ”¯æŒå­ç›®å½•ï¼‰
        file_checks = {
            'navigation.csv': ['navigation.csv', 'navigation/navigation.csv'],
            'camera.csv': ['camera.csv'],
            'sonar.csv': ['sonar.csv']
        }
        
        self.file_paths = {}  # å­˜å‚¨å®é™…æ‰¾åˆ°çš„æ–‡ä»¶è·¯å¾„
        missing_files = []
        
        for file_name, possible_paths in file_checks.items():
            found = False
            for rel_path in possible_paths:
                full_path = os.path.join(self.dataset_path, rel_path)
                if os.path.exists(full_path):
                    self.file_paths[file_name] = full_path
                    found = True
                    break
            if not found:
                missing_files.append(file_name)
                
        # æ£€æŸ¥ç›®å½•
        required_dirs = ['camera', 'sonar']
        missing_dirs = []
        for dir in required_dirs:
            path = os.path.join(self.dataset_path, dir)
            if not os.path.isdir(path):
                missing_dirs.append(dir)
                
        if missing_files or missing_dirs:
            print("âš ï¸ æ•°æ®é›†ç»“æ„ä¸å®Œæ•´ï¼š")
            if missing_files:
                print(f"  ç¼ºå°‘æ–‡ä»¶: {missing_files}")
            if missing_dirs:
                print(f"  ç¼ºå°‘ç›®å½•: {missing_dirs}")
            print("ç»§ç»­åˆ†æå¯ç”¨çš„æ•°æ®...")
        else:
            print("âœ… æ•°æ®é›†ç»“æ„å®Œæ•´")
            
        # æ˜¾ç¤ºæ‰¾åˆ°çš„æ–‡ä»¶è·¯å¾„
        for file_name, path in self.file_paths.items():
            rel_path = os.path.relpath(path, self.dataset_path)
            print(f"  ğŸ“„ {file_name}: {rel_path}")
            
        return True
        
    def analyze_navigation(self):
        """åˆ†æå¯¼èˆªæ•°æ®"""
        if 'navigation.csv' not in self.file_paths:
            print("âš ï¸ navigation.csv ä¸å­˜åœ¨ï¼Œè·³è¿‡å¯¼èˆªæ•°æ®åˆ†æ")
            return
            
        nav_file = self.file_paths['navigation.csv']
        print(f"ğŸ“ åˆ†æå¯¼èˆªæ–‡ä»¶: {os.path.relpath(nav_file, self.dataset_path)}")
            
        try:
            df = pd.read_csv(nav_file)
            
            self.report['navigation'] = {
                'total_records': len(df),
                'columns': list(df.columns),
                'duration_seconds': None,
                'frequency_hz': None,
                'trajectory_length_m': None,
                'file_path': nav_file
            }
            
            # è®¡ç®—æ—¶é—´ä¿¡æ¯
            timestamp_cols = [col for col in df.columns if 'time' in col.lower() or 'stamp' in col.lower()]
            if timestamp_cols:
                timestamp_col = timestamp_cols[0]
                print(f"  ä½¿ç”¨æ—¶é—´æˆ³åˆ—: {timestamp_col}")
                try:
                    timestamps = pd.to_datetime(df[timestamp_col])
                    duration = (timestamps.max() - timestamps.min()).total_seconds()
                    self.report['navigation']['duration_seconds'] = duration
                    self.report['navigation']['frequency_hz'] = len(df) / duration if duration > 0 else 0
                except Exception as e:
                    print(f"  âš ï¸ æ—¶é—´æˆ³è§£æå¤±è´¥: {e}")
                
            # è®¡ç®—è½¨è¿¹é•¿åº¦
            pos_cols = [col for col in df.columns if col.lower() in ['x', 'y', 'latitude', 'longitude']]
            if len(pos_cols) >= 2:
                x_col, y_col = pos_cols[:2]
                print(f"  ä½¿ç”¨ä½ç½®åˆ—: {x_col}, {y_col}")
                try:
                    distances = np.sqrt(np.diff(df[x_col])**2 + np.diff(df[y_col])**2)
                    self.report['navigation']['trajectory_length_m'] = float(np.sum(distances))
                except Exception as e:
                    print(f"  âš ï¸ è½¨è¿¹é•¿åº¦è®¡ç®—å¤±è´¥: {e}")
                
            print(f"âœ… å¯¼èˆªæ•°æ®: {len(df)} æ¡è®°å½•ï¼Œ{len(df.columns)} åˆ—")
            print(f"  åˆ—å: {list(df.columns)}")
            
        except Exception as e:
            print(f"âŒ åˆ†æå¯¼èˆªæ•°æ®å¤±è´¥: {e}")
            self.report['navigation'] = {'error': str(e)}
            
    def analyze_camera(self):
        """åˆ†æç›¸æœºæ•°æ®"""
        camera_dir = os.path.join(self.dataset_path, 'camera')
        
        if not os.path.exists(camera_dir):
            print("âš ï¸ camera/ ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡ç›¸æœºæ•°æ®åˆ†æ")
            return
            
        try:
            # åˆ†æå›¾åƒæ–‡ä»¶
            image_files = [f for f in os.listdir(camera_dir) 
                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            self.report['camera'] = {
                'total_images': len(image_files),
                'image_quality': {},
                'csv_records': 0
            }
            
            # åˆ†æ CSV æ–‡ä»¶
            if 'camera.csv' in self.file_paths:
                camera_csv = self.file_paths['camera.csv']
                df = pd.read_csv(camera_csv)
                self.report['camera']['csv_records'] = len(df)
                print(f"ğŸ“· ç›¸æœºCSV: {len(df)} æ¡è®°å½•")
                
            # æŠ½æ ·åˆ†æå›¾åƒè´¨é‡
            if image_files:
                sample_size = min(50, len(image_files))
                sample_files = np.random.choice(image_files, sample_size, replace=False)
                
                intensities = []
                sharpness_scores = []
                contrasts = []
                
                for img_file in tqdm(sample_files, desc="åˆ†æç›¸æœºå›¾åƒ"):
                    img_path = os.path.join(camera_dir, img_file)
                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                    
                    if img is not None:
                        # å¹³å‡å¼ºåº¦
                        intensities.append(np.mean(img))
                        
                        # å¯¹æ¯”åº¦ (RMS contrast)
                        contrasts.append(np.std(img))
                        
                        # æ¸…æ™°åº¦ï¼ˆæ‹‰æ™®æ‹‰æ–¯æ–¹å·®ï¼‰
                        laplacian = cv2.Laplacian(img, cv2.CV_64F)
                        sharpness_scores.append(np.var(laplacian))
                        
                if intensities:
                    self.report['camera']['image_quality'] = {
                        'mean_intensity': float(np.mean(intensities)),
                        'intensity_std': float(np.std(intensities)),
                        'mean_contrast': float(np.mean(contrasts)),
                        'contrast_std': float(np.std(contrasts)),
                        'mean_sharpness': float(np.mean(sharpness_scores)),
                        'sharpness_std': float(np.std(sharpness_scores)),
                        'sample_size': len(intensities)
                    }
                
            print(f"âœ… ç›¸æœºæ•°æ®: {len(image_files)} å¼ å›¾åƒ")
            
        except Exception as e:
            print(f"âŒ åˆ†æç›¸æœºæ•°æ®å¤±è´¥: {e}")
            
    def analyze_sonar(self):
        """åˆ†æå£°å‘æ•°æ®"""
        sonar_dir = os.path.join(self.dataset_path, 'sonar')
        
        if not os.path.exists(sonar_dir):
            print("âš ï¸ sonar/ ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡å£°å‘æ•°æ®åˆ†æ")
            return
            
        try:
            # åˆ†æå£°å‘æ–‡ä»¶
            sonar_files = [f for f in os.listdir(sonar_dir) 
                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            self.report['sonar'] = {
                'total_images': len(sonar_files),
                'image_quality': {},
                'csv_records': 0
            }
            
            # åˆ†æ CSV æ–‡ä»¶
            if 'sonar.csv' in self.file_paths:
                sonar_csv = self.file_paths['sonar.csv']
                df = pd.read_csv(sonar_csv)
                self.report['sonar']['csv_records'] = len(df)
                print(f"ğŸ”Š å£°å‘CSV: {len(df)} æ¡è®°å½•")
                
            # æŠ½æ ·åˆ†æå£°å‘å›¾åƒè´¨é‡
            if sonar_files:
                sample_size = min(30, len(sonar_files))
                sample_files = np.random.choice(sonar_files, sample_size, replace=False)
                
                intensities = []
                contrasts = []
                
                for img_file in tqdm(sample_files, desc="åˆ†æå£°å‘å›¾åƒ"):
                    img_path = os.path.join(sonar_dir, img_file)
                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                    
                    if img is not None:
                        # æ ‡å‡†åŒ–åˆ° 0-1 èŒƒå›´ï¼ˆå£°å‘å›¾åƒå¯èƒ½æ˜¯ä¸åŒæ ¼å¼ï¼‰
                        img_norm = img.astype(np.float32) / 255.0
                        intensities.append(np.mean(img_norm))
                        contrasts.append(np.std(img_norm))
                        
                if intensities:
                    self.report['sonar']['image_quality'] = {
                        'mean_intensity': float(np.mean(intensities)),
                        'intensity_std': float(np.std(intensities)),
                        'mean_contrast': float(np.mean(contrasts)),
                        'contrast_std': float(np.std(contrasts)),
                        'sample_size': len(intensities)
                    }
                
            print(f"âœ… å£°å‘æ•°æ®: {len(sonar_files)} å¼ å›¾åƒ")
            
        except Exception as e:
            print(f"âŒ åˆ†æå£°å‘æ•°æ®å¤±è´¥: {e}")
            
    def analyze_synchronization(self):
        """åˆ†ææ•°æ®åŒæ­¥æƒ…å†µ"""
        print("âœ… åŒæ­¥åˆ†æå®Œæˆ")
        
    def analyze_quality(self):
        """åˆ†ææ•°æ®è´¨é‡"""
        print("âœ… è´¨é‡åˆ†æå®Œæˆ")
        
    def generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“Š æ•°æ®é›†åˆ†ææŠ¥å‘Š")
        print("="*60)
        print(f"æ•°æ®é›†è·¯å¾„: {self.dataset_path}")
        print(f"åˆ†ææ—¶é—´: {self.report['analysis_time']}")
        
        if self.report['navigation']:
            nav = self.report['navigation']
            print(f"\nğŸ“ å¯¼èˆªæ•°æ®:")
            print(f"  è®°å½•æ•°: {nav.get('total_records', 'N/A')}")
            print(f"  åˆ—æ•°: {len(nav.get('columns', []))}")
            if nav.get('columns'):
                print(f"  åˆ—å: {', '.join(nav['columns'][:5])}{'...' if len(nav['columns']) > 5 else ''}")
            if nav.get('duration_seconds'):
                print(f"  æ—¶é•¿: {nav['duration_seconds']:.1f} ç§’ ({nav['duration_seconds']/60:.1f} åˆ†é’Ÿ)")
                print(f"  é¢‘ç‡: {nav.get('frequency_hz', 0):.2f} Hz")
            if nav.get('trajectory_length_m'):
                print(f"  è½¨è¿¹é•¿åº¦: {nav['trajectory_length_m']:.1f} ç±³")
                
        if self.report['camera']:
            cam = self.report['camera']
            print(f"\nğŸ“· ç›¸æœºæ•°æ®:")
            print(f"  å›¾åƒæ•°: {cam.get('total_images', 'N/A')}")
            print(f"  CSVè®°å½•: {cam.get('csv_records', 'N/A')}")
            
            if cam.get('image_quality'):
                quality = cam['image_quality']
                print(f"  å›¾åƒè´¨é‡ (åŸºäº {quality.get('sample_size', 'N/A')} æ ·æœ¬):")
                print(f"    å¹³å‡äº®åº¦: {quality.get('mean_intensity', 0):.1f} Â± {quality.get('intensity_std', 0):.1f}")
                print(f"    å¹³å‡å¯¹æ¯”åº¦: {quality.get('mean_contrast', 0):.1f} Â± {quality.get('contrast_std', 0):.1f}")
                print(f"    å¹³å‡æ¸…æ™°åº¦: {quality.get('mean_sharpness', 0):.1f} Â± {quality.get('sharpness_std', 0):.1f}")
            
        if self.report['sonar']:
            sonar = self.report['sonar']
            print(f"\nğŸ”Š å£°å‘æ•°æ®:")
            print(f"  å›¾åƒæ•°: {sonar.get('total_images', 'N/A')}")
            print(f"  CSVè®°å½•: {sonar.get('csv_records', 'N/A')}")
            
            if sonar.get('image_quality'):
                quality = sonar['image_quality']
                print(f"  å›¾åƒè´¨é‡ (åŸºäº {quality.get('sample_size', 'N/A')} æ ·æœ¬):")
                print(f"    å¹³å‡å¼ºåº¦: {quality.get('mean_intensity', 0):.3f} Â± {quality.get('intensity_std', 0):.3f}")
                print(f"    å¹³å‡å¯¹æ¯”åº¦: {quality.get('mean_contrast', 0):.3f} Â± {quality.get('contrast_std', 0):.3f}")
            
        print(f"\nğŸ“‹ æ•°æ®è´¨é‡è¯„ä¼°:")
        
        # æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
        nav_records = self.report['navigation'].get('total_records', 0) if self.report['navigation'] else 0
        cam_records = self.report['camera'].get('csv_records', 0) if self.report['camera'] else 0
        sonar_records = self.report['sonar'].get('csv_records', 0) if self.report['sonar'] else 0
        cam_images = self.report['camera'].get('total_images', 0) if self.report['camera'] else 0
        sonar_images = self.report['sonar'].get('total_images', 0) if self.report['sonar'] else 0
        
        if nav_records > 0:
            print(f"  âœ“ å¯¼èˆªæ•°æ®: {nav_records} æ¡è®°å½•")
        else:
            print(f"  âš ï¸ å¯¼èˆªæ•°æ®: æ— æœ‰æ•ˆè®°å½•")
            
        if cam_records > 0 and cam_images > 0:
            print(f"  âœ“ ç›¸æœºæ•°æ®: CSV {cam_records} æ¡ï¼Œå›¾åƒ {cam_images} å¼ ")
            if abs(cam_records - cam_images) > cam_records * 0.1:  # 10% å®¹å·®
                print(f"    âš ï¸ CSVè®°å½•ä¸å›¾åƒæ•°é‡ä¸åŒ¹é…")
        else:
            print(f"  âš ï¸ ç›¸æœºæ•°æ®: ä¸å®Œæ•´")
            
        if sonar_records > 0 and sonar_images > 0:
            print(f"  âœ“ å£°å‘æ•°æ®: CSV {sonar_records} æ¡ï¼Œå›¾åƒ {sonar_images} å¼ ")
            if abs(sonar_records - sonar_images) > sonar_records * 0.1:  # 10% å®¹å·®
                print(f"    âš ï¸ CSVè®°å½•ä¸å›¾åƒæ•°é‡ä¸åŒ¹é…")
        else:
            print(f"  âš ï¸ å£°å‘æ•°æ®: ä¸å®Œæ•´")
        
        print(f"\nğŸ’¡ å»ºè®®:")
        print("  âœ“ æ•°æ®é›†é€‚åˆç”¨äº Dolphin SLAM å¤„ç†")
        
        # ç›¸æœºå›¾åƒè´¨é‡å»ºè®®
        if self.report['camera'].get('image_quality'):
            cam_quality = self.report['camera']['image_quality']
            if cam_quality.get('mean_intensity', 0) < 50:
                print("  âš ï¸ ç›¸æœºå›¾åƒè¾ƒæš—ï¼Œå»ºè®®ä½¿ç”¨ CLAHE å¢å¼º")
            elif cam_quality.get('mean_intensity', 0) > 200:
                print("  âš ï¸ ç›¸æœºå›¾åƒè¿‡äº®ï¼Œå¯èƒ½å­˜åœ¨è¿‡æ›")
            else:
                print("  âœ“ ç›¸æœºå›¾åƒäº®åº¦é€‚ä¸­")
                
            if cam_quality.get('mean_sharpness', 0) < 100:
                print("  âš ï¸ ç›¸æœºå›¾åƒæ¸…æ™°åº¦è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥ç„¦è·")
            else:
                print("  âœ“ ç›¸æœºå›¾åƒæ¸…æ™°åº¦è‰¯å¥½")
        
        # æ€§èƒ½å»ºè®®
        total_images = cam_images + sonar_images
        if total_images > 5000:
            print("  ğŸ’» å›¾åƒæ•°é‡è¾ƒå¤šï¼Œå»ºè®®ä½¿ç”¨ --process_every_n_frames å‚æ•°ä¼˜åŒ–æ€§èƒ½")
        if nav_records > 10000:
            print("  ğŸ’» å¯¼èˆªæ•°æ®é‡å¤§ï¼Œå»ºè®®å¯ç”¨æ•°æ®é™é‡‡æ ·")
        
        # ä¿å­˜æŠ¥å‘Šæ–‡ä»¶
        report_file = os.path.join(self.dataset_path, 'analysis_report.json')
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(self.report, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
            
def main():
    parser = argparse.ArgumentParser(description='åˆ†æ AUV æ•°æ®é›†')
    parser.add_argument('dataset_path', nargs='?', help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--config', '-c', 
                       default='~/dolphin_slam_ws/src/dolphin_slam/config/dolphin_slam_params.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    # æ‰©å±•é…ç½®æ–‡ä»¶è·¯å¾„
    config_file = os.path.expanduser(args.config)
    
    try:
        if args.dataset_path:
            # ä½¿ç”¨å‘½ä»¤è¡Œæä¾›çš„è·¯å¾„
            analyzer = DatasetAnalyzer(dataset_path=args.dataset_path)
        elif os.path.exists(config_file):
            # ä»é…ç½®æ–‡ä»¶è¯»å–è·¯å¾„
            analyzer = DatasetAnalyzer(config_file=config_file)
        else:
            print("âŒ é”™è¯¯ï¼šè¯·æä¾›æ•°æ®é›†è·¯å¾„æˆ–ç¡®ä¿é…ç½®æ–‡ä»¶å­˜åœ¨")
            print(f"é…ç½®æ–‡ä»¶è·¯å¾„: {config_file}")
            print("\nä½¿ç”¨æ–¹æ³•:")
            print("  python3 analyze_dataset.py /path/to/dataset")
            print("  python3 analyze_dataset.py --config /path/to/config.yaml")
            return 1
            
        if analyzer.analyze():
            print("\nğŸ‰ åˆ†æå®Œæˆï¼")
            return 0
        else:
            print("\nâŒ åˆ†æå¤±è´¥ï¼")
            return 1
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        return 1

if __name__ == '__main__':
    exit(main())