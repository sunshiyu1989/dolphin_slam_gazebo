#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆå›¾åƒå¤„ç†èŠ‚ç‚¹ - è¿æ¥Gazeboå®æ—¶ä¼ æ„Ÿå™¨
"""

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from visualization_msgs.msg import MarkerArray, Marker
from cv_bridge import CvBridge
import cv2
import numpy as np
from typing import Optional

class ImageProcessingNode(Node):
    """ä¿®å¤ç‰ˆå›¾åƒå¤„ç†èŠ‚ç‚¹"""
    
    def __init__(self):
        super().__init__('image_processing_node')
        
        # å‚æ•°é…ç½®
        self.camera_topic = '/forward_camera/image_raw'
        self.sonar_topic = '/sonar/image_raw'
        self.descriptors_topic = '/features/descriptors'
        self.keypoints_topic = '/features/keypoints'
        self.feature_type = 'SIFT'
        self.max_features = 300
        self.process_every_n = 3
        self.enable_viz = True
        self.debug_mode = True
        
        # CV Bridge
        self.bridge = CvBridge()
        
        # åˆå§‹åŒ–ç‰¹å¾æ£€æµ‹å™¨
        self._init_feature_detector()
        
        # å¸§è®¡æ•°å™¨
        self.camera_frame_count = 0
        self.processed_frames = 0
        
        # è®¢é˜…è€… - é‡ç‚¹ï¼šç¡®ä¿æ­£ç¡®çš„è¯é¢˜
        self.camera_sub = self.create_subscription(
            Image,
            self.camera_topic,
            self.camera_callback,
            10
        )
        
        # å‘å¸ƒè€…
        self.descriptors_pub = self.create_publisher(
            Image,
            self.descriptors_topic,
            10
        )
        
        self.keypoints_pub = self.create_publisher(
            MarkerArray,
            self.keypoints_topic,
            10
        )
        
        # å¯è§†åŒ–å‘å¸ƒè€…
        self.camera_features_pub = self.create_publisher(
            Image,
            '/camera/image_features',
            10
        )
        
        # å®šæ—¶å™¨ç”¨äºçŠ¶æ€æŠ¥å‘Š
        self.report_timer = self.create_timer(5.0, self.report_status)
        
        self.get_logger().info(f'ğŸ¯ ä¿®å¤ç‰ˆå›¾åƒå¤„ç†èŠ‚ç‚¹å·²å¯åŠ¨')
        self.get_logger().info(f'ğŸ“· è®¢é˜…ç›¸æœºè¯é¢˜: {self.camera_topic}')
        self.get_logger().info(f'ğŸ” ä½¿ç”¨ç‰¹å¾: {self.feature_type}, æœ€å¤§ç‰¹å¾æ•°: {self.max_features}')
        
    def _init_feature_detector(self):
        """åˆå§‹åŒ–ç‰¹å¾æ£€æµ‹å™¨"""
        try:
            if self.feature_type.upper() == 'SIFT':
                self.detector = cv2.SIFT_create(nfeatures=self.max_features)
            elif self.feature_type.upper() == 'ORB':
                self.detector = cv2.ORB_create(nfeatures=self.max_features)
            else:
                # é»˜è®¤ä½¿ç”¨SIFT
                self.detector = cv2.SIFT_create(nfeatures=self.max_features)
                
            self.get_logger().info(f'âœ… {self.feature_type} ç‰¹å¾æ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ')
            
        except Exception as e:
            self.get_logger().error(f'âŒ ç‰¹å¾æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}')
            # å¤‡ç”¨æ–¹æ¡ˆ
            self.detector = cv2.ORB_create(nfeatures=self.max_features)
            
    def camera_callback(self, msg: Image):
        """å¤„ç†ç›¸æœºå›¾åƒ"""
        self.camera_frame_count += 1
        
        # è·³å¸§å¤„ç†
        if self.camera_frame_count % self.process_every_n != 0:
            return
            
        try:
            # è½¬æ¢ä¸ºOpenCVæ ¼å¼
            cv_image = self.bridge.imgmsg_to_cv2(msg, 'bgr8')
            
            # è½¬ä¸ºç°åº¦å›¾
            if len(cv_image.shape) == 3:
                gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
            else:
                gray = cv_image
                
            # åº”ç”¨CLAHEå¯¹æ¯”åº¦å¢å¼ºï¼ˆæ°´ä¸‹ç¯å¢ƒé‡è¦ï¼‰
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            # ç‰¹å¾æ£€æµ‹å’Œæè¿°
            keypoints, descriptors = self.detector.detectAndCompute(enhanced, None)
            
            if descriptors is not None and len(keypoints) > 0:
                # å‘å¸ƒæè¿°ç¬¦ï¼ˆç®€åŒ–ç‰ˆæœ¬ - ä½¿ç”¨å›¾åƒæ¶ˆæ¯ï¼‰
                self._publish_descriptors(descriptors, msg.header)
                
                # å‘å¸ƒå…³é”®ç‚¹å¯è§†åŒ–
                self._publish_keypoints(keypoints, msg.header)
                
                # å¯è§†åŒ–ç‰¹å¾ç‚¹
                if self.enable_viz:
                    self._publish_features_visualization(cv_image, keypoints)
                
                self.processed_frames += 1
                
                # ğŸ”§ é™ä½æ—¥å¿—è¾“å‡ºé¢‘ç‡ - æ¯100æ¬¡å¤„ç†æ˜¾ç¤ºä¸€æ¬¡
                if not hasattr(self, '_process_count'):
                    self._process_count = 0
                self._process_count += 1
                
                if self._process_count % 100 == 1:
                    processing_rate = (self.processed_frames / self.camera_frame_count * 100) if self.camera_frame_count > 0 else 0
                    self.get_logger().info(
                        f'ğŸ“Š å›¾åƒå¤„ç†çŠ¶æ€: æ¥æ”¶{self.camera_frame_count}å¸§, '
                        f'å¤„ç†{self.processed_frames}å¸§, å¤„ç†ç‡{processing_rate:.1f}%'
                    )
            else:
                # ğŸ”§ å‡å°‘è­¦å‘Šé¢‘ç‡ - æ¯100å¸§æ˜¾ç¤ºä¸€æ¬¡
                if self.debug_mode and self.camera_frame_count % 100 == 0:
                    self.get_logger().warn(f'âš ï¸ å¸§#{self.camera_frame_count}: æœªæ£€æµ‹åˆ°ç‰¹å¾ç‚¹')
                    
        except Exception as e:
            self.get_logger().error(f'âŒ å›¾åƒå¤„ç†å¤±è´¥: {e}')
            
    def _publish_descriptors(self, descriptors, header):
        """å‘å¸ƒæè¿°ç¬¦æ•°æ®"""
        try:
            # å°†æè¿°ç¬¦è½¬æ¢ä¸ºå›¾åƒæ ¼å¼ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰
            # æ­£å¸¸åº”è¯¥ä½¿ç”¨è‡ªå®šä¹‰æ¶ˆæ¯ç±»å‹
            desc_normalized = descriptors.astype(np.float32)
            
            # å½’ä¸€åŒ–åˆ°0-255èŒƒå›´
            if desc_normalized.max() > 0:
                desc_normalized = (desc_normalized / desc_normalized.max() * 255).astype(np.uint8)
            
            # ç¡®ä¿æ˜¯2Då›¾åƒæ ¼å¼
            if len(desc_normalized.shape) == 1:
                desc_normalized = desc_normalized.reshape(1, -1)
                
            # åˆ›å»ºå›¾åƒæ¶ˆæ¯
            desc_msg = self.bridge.cv2_to_imgmsg(desc_normalized, 'mono8')
            desc_msg.header = header
            
            self.descriptors_pub.publish(desc_msg)
            
        except Exception as e:
            self.get_logger().error(f'âŒ æè¿°ç¬¦å‘å¸ƒå¤±è´¥: {e}')
            
    def _publish_keypoints(self, keypoints, header):
        """å‘å¸ƒå…³é”®ç‚¹å¯è§†åŒ–"""
        try:
            markers = MarkerArray()
            
            for i, kp in enumerate(keypoints[:50]):  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                marker = Marker()
                marker.header = header
                marker.header.frame_id = "camera_link"
                marker.ns = "keypoints"
                marker.id = i
                marker.type = Marker.SPHERE
                marker.action = Marker.ADD
                
                # å…³é”®ç‚¹ä½ç½®ï¼ˆç®€åŒ–æ˜ å°„åˆ°3Dï¼‰
                marker.pose.position.x = float(kp.pt[0] / 1000.0)  # ç¼©æ”¾
                marker.pose.position.y = float(kp.pt[1] / 1000.0)
                marker.pose.position.z = 0.1
                marker.pose.orientation.w = 1.0
                
                # æ ‡è®°å¤§å°å’Œé¢œè‰²
                marker.scale.x = 0.02
                marker.scale.y = 0.02
                marker.scale.z = 0.02
                
                marker.color.a = 1.0
                marker.color.r = 1.0
                marker.color.g = 0.0
                marker.color.b = 0.0
                
                marker.lifetime.sec = 1
                
                markers.markers = list(markers.markers) + [marker]
                
            self.keypoints_pub.publish(markers)
            
        except Exception as e:
            self.get_logger().error(f'âŒ å…³é”®ç‚¹å‘å¸ƒå¤±è´¥: {e}')
            
    def _publish_features_visualization(self, image, keypoints):
        """å‘å¸ƒå¸¦ç‰¹å¾ç‚¹çš„å›¾åƒå¯è§†åŒ–"""
        try:
            # ç»˜åˆ¶ç‰¹å¾ç‚¹
            img_with_keypoints = cv2.drawKeypoints(
                image, keypoints, None, 
                color=(0, 255, 0), 
                flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS
            )
            
            # å‘å¸ƒå¯è§†åŒ–å›¾åƒ
            viz_msg = self.bridge.cv2_to_imgmsg(img_with_keypoints, 'bgr8')
            self.camera_features_pub.publish(viz_msg)
            
        except Exception as e:
            self.get_logger().error(f'âŒ å¯è§†åŒ–å‘å¸ƒå¤±è´¥: {e}')
            
    def report_status(self):
        """çŠ¶æ€æŠ¥å‘Š"""
        self.get_logger().info(
            f'ğŸ“Š å›¾åƒå¤„ç†çŠ¶æ€: æ¥æ”¶{self.camera_frame_count}å¸§, '
            f'å¤„ç†{self.processed_frames}å¸§, '
            f'å¤„ç†ç‡{self.processed_frames/max(self.camera_frame_count,1)*100:.1f}%'
        )

def main(args=None):
    rclpy.init(args=args)
    
    try:
        node = ImageProcessingNode()
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        if rclpy.ok():
            rclpy.shutdown()

if __name__ == '__main__':
    main()
